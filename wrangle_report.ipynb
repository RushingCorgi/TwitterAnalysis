{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this twitter data wrangling project, I conducted data gathering, data assessing and data cleaning in three different section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I gathered tweet data from three different sources: WeRateDogs' Twitter archive downloaded from Udacity project summary page, dog breed image prediction tsv file from Udacity server, and tweet JSON data.\n",
    "\n",
    "Obtaining the archive file is easy. I just downloaded it and load it into jupyter notebook by pandas.read_csv().\n",
    "\n",
    "Gathering image predition tsv file is a little more tricky. I used Python package 'requests' to load the flat file content in to the memory and converted it as dataframe in jupyter notebook by pandas.read_csv( ) method and the text manager i0.StringIO( ).\n",
    "\n",
    "Extracing the JSON data by Twitter API tweepy is the most difficult one. I queried tweet objects by API.statuses_lookup( ) which gives me at most 100 tweet objects each time so that I don't reach the rating limit of tweepy. Then I saved the JSON files as a .txt file using text manager in python. In this file I added favorite counts and retweeted counts to the archive dataframe in cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these section, I assessed the three datasets visually and programmatically. The most data quality and tidiness issue were found in the archive dataframe. \n",
    "\n",
    "There were data values that actually do not exist such as missing values in in_reply_to fields and retweeted_status fields; missing dog names and dog types. In the meaning while, the missing value of expanded urls can be fixed in some degree by using a formal expression 'https://twitter.com/dog_rates/status/tweet_id'. If the tweets still exist, then the expression is valid.\n",
    "\n",
    "There were also invalid datatype of several variables. For example, id fields should be saved as integers rather than float numbers and timestamp fields should be saved as datetime objects.\n",
    "\n",
    "The accuracy issues happened in dog names and dog rates columns. Other words or digits were recorded by regular expressions which was not strict enough.\n",
    "\n",
    "The data tidiness issues is easier to find than other issues above. The dog information and tweet information should be stored in separate tables. Dog stage information should be stored in one column as a categorical variable. Multiple dog stages shown in one tweet actually describled two different dogs in the corresponding figure, or the author collected wrong stages which was not to describle the dog in the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I cleaned all data issues except for some missing value issues detected above. To clean the datasets, I first extracted dog rates again using a more strict rule: extract digits with non-zero denominator ended in 0, because I found @dog_rates always rate dogs with denominator as multiples of ten. I also created a new column to store rating values which equals to the rating numerator divided by the rating denominator.\n",
    "\n",
    "Then I used archive dataframe, image prediction dataframe and JSON dataframe to form two new tables to store tweets information and dog information.\n",
    "\n",
    "In tweet dataframe, I added missing expanded urls in the formal expression mentioned above. In order to change float type columns with null values into int type, I transformed null values as integer -1 and other values as int type, because adding null values to int type column will transform it as float type automatically. I transformed timestamp fields from string to datetime objects using pandas.to_datetime( ) function.\n",
    "\n",
    "In dog information dataframe, I remedied the dog stage issues by saving dog stage as a single column, and I saved different stages for different dogs with same tweet id in different rows. In the meanwhile, I deleted wrong stages by maually by checking the tweets' text. I detected the wrong dog names using Python package 'nltk'. Dog names be tagged as non-noun types must be wrong. The invalid dog names has been changed as string 'None'. The last thing in this section is to add a column to store dog breed information. The dog breed is predicted by neural network and is saved in image prediction table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
